# DECLARE ENTITIES
flumeagent.sources = s1
flumeagent.channels = file-channel2
flumeagent.sinks = kafka-avro-sink

# CONFIGURE SOURCE
flumeagent.sources.s1.type = spooldir
flumeagent.sources.s1.channels = file-channel2
flumeagent.sources.s1.spoolDir = /home/vagrant/logs/HAEBDK/NEU
flumeagent.sources.s1.fileHeader = false
flumeagent.sources.s1.deletePolicy = never
flumeagent.sources.s1.deserializer = LINE
flumeagent.sources.s1.deserializer.maxLineLength = 100000

# CONFIGURE CHANNEL
flumeagent.channels.file-channel2.type = file
flumeagent.channels.file-channel2.checkpointDir = /home/vagrant/flume-channel/checkpoint
flumeagent.channels.file-channel2.dataDirs = /home/vagrant/flume-channel/data
flumeagent.channels.file-channel2.capacity = 10000
flumeagent.channels.file-channel2.transactionCapacity = 10000

# CONFIGURE SINK 1
flumeagent.sinks.kafka-avro-sink.type = com.scigility.postlogistics.flume.KafkaAvroSink
flumeagent.sinks.kafka-avro-sink.channel = file-channel2

# topic, schema file and schema registry url
flumeagent.sinks.kafka-avro-sink.topic = log_haebdk_offline9
flumeagent.sinks.kafka-avro-sink.avro.schema.file = /home/vagrant/res/Fehlverhalten_HAEBDK_avro_NEU.json
flumeagent.sinks.kafka-avro-sink.kafka.schema.registry.url = http://local.cm5.com:8081

# other producer configs
flumeagent.sinks.kafka-avro-sink.parser.class = com.scigility.postlogistics.flume.HaebdkParser_NEU
flumeagent.sinks.kafka-avro-sink.kafka.batch.size = 100
flumeagent.sinks.kafka-avro-sink.kafka.bootstrap.servers = local.cm5.com:9092
flumeagent.sinks.kafka-avro-sink.kafka.key.serializer = io.confluent.kafka.serializers.KafkaAvroSerializer
flumeagent.sinks.kafka-avro-sink.kafka.value.serializer = io.confluent.kafka.serializers.KafkaAvroSerializer
flumeagent.sinks.kafka-avro-sink.kafka.acks=1
flumeagent.sinks.kafka-avro-sink.kafka.compression.type = snappy
flumeagent.sinks.kafka-avro-sink.kafka.linger.ms = 100

